{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 2 — Thème 2 : CSV/Excel + Power Query (validation notebook)\\n",
        "\\n",
        "Ce notebook génère :\\n",
        "- `m2t2_clean_learning_dataset.csv`\\n",
        "- `m2t2_quality_report.json`\\n",
        "- `m2t2_data_dictionary.md`\\n",
        "\\n",
        "Et vérifie que `m2t2_powerquery.m` existe (script M collé par l’étudiant).\\n",
        "\\n",
        "Entrées attendues dans le même dossier :\\n",
        "- `raw_events_messy.csv`\\n",
        "- `raw_profiles_messy.xlsx`\\n",
        "- `m2t2_powerquery.m` (à créer par l’étudiant)\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1 — Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\\n",
        "import json\\n",
        "import pandas as pd\\n",
        "from datetime import datetime\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2 — Robust CSV reader (separator + encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_csv_robust(path: str) -> pd.DataFrame:\\n",
        "    attempts = [\\n",
        "        {\"sep\": \";\", \"encoding\": \"utf-8\"},\\n",
        "        {\"sep\": \",\", \"encoding\": \"utf-8\"},\\n",
        "        {\"sep\": \";\", \"encoding\": \"latin1\"},\\n",
        "        {\"sep\": \",\", \"encoding\": \"latin1\"},\\n",
        "    ]\\n",
        "    last_err = None\\n",
        "    for a in attempts:\\n",
        "        try:\\n",
        "            df = pd.read_csv(path, **a)\\n",
        "            # quick sanity: must have at least 3 columns\\n",
        "            if df.shape[1] >= 3:\\n",
        "                return df\\n",
        "        except Exception as e:\\n",
        "            last_err = e\\n",
        "    raise last_err\\n",
        "\\n",
        "events = read_csv_robust(\"raw_events_messy.csv\")\\n",
        "print(\"Loaded events:\", events.shape)\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2bis — Robust Excel reader (find header row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_profiles_robust(path: str) -> pd.DataFrame:\\n",
        "    # First read without header to locate the row containing 'user_id'\\n",
        "    raw = pd.read_excel(path, sheet_name=0, header=None)\\n",
        "    header_row = None\\n",
        "    for i in range(min(10, len(raw))):\\n",
        "        row_vals = [str(v).strip().lower() for v in raw.iloc[i].tolist()]\\n",
        "        if \"user_id\" in row_vals:\\n",
        "            header_row = i\\n",
        "            break\\n",
        "    if header_row is None:\\n",
        "        # fallback: assume first row is header\\n",
        "        return pd.read_excel(path, sheet_name=0)\\n",
        "    return pd.read_excel(path, sheet_name=0, header=header_row)\\n",
        "\\n",
        "profiles = read_profiles_robust(\"raw_profiles_messy.xlsx\")\\n",
        "print(\"Loaded profiles:\", profiles.shape)\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3 — Standardize column names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "events.columns = [str(c).strip().lower() for c in events.columns]\\n",
        "profiles.columns = [str(c).strip().lower() for c in profiles.columns]\\n",
        "\\n",
        "# tolerant aliasing if needed\\n",
        "aliases = {\\n",
        "    \"userid\": \"user_id\",\\n",
        "    \"user\": \"user_id\",\\n",
        "    \"time\": \"event_time\",\\n",
        "    \"timestamp\": \"event_time\",\\n",
        "    \"event\": \"event_type\"\\n",
        "}\\n",
        "for k, v in aliases.items():\\n",
        "    if k in events.columns and v not in events.columns:\\n",
        "        events.rename(columns={k: v}, inplace=True)\\n",
        "\\n",
        "print(\"Events columns:\", list(events.columns))\\n",
        "print(\"Profiles columns:\", list(profiles.columns))\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4 — Cleaning helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_str(s: pd.Series) -> pd.Series:\\n",
        "    s = s.astype(str)\\n",
        "    s = s.str.replace(\"\\u00A0\", \" \", regex=False)  # non-breaking space\\n",
        "    s = s.str.strip()\\n",
        "    s = s.str.replace(r\"\\s+\", \" \", regex=True)\\n",
        "    # pandas sometimes turns NaN into \"nan\" string after astype(str)\\n",
        "    s = s.replace(\"nan\", \"\")\\n",
        "    return s\\n",
        "\\n",
        "def normalize_country(s: pd.Series) -> pd.Series:\\n",
        "    s = clean_str(s)\\n",
        "    s = s.str.title()\\n",
        "    # optional harmonization\\n",
        "    s = s.replace({\"Benin\": \"Bénin\"})\\n",
        "    return s\\n",
        "\\n",
        "def normalize_channel(s: pd.Series) -> pd.Series:\\n",
        "    s = clean_str(s).str.lower()\\n",
        "    s = s.replace({\"cellulaire\": \"mobile\", \"smartphone\": \"mobile\"})\\n",
        "    return s\\n",
        "\\n",
        "def normalize_event_type(s: pd.Series) -> pd.Series:\\n",
        "    s = clean_str(s).str.lower()\\n",
        "    s = s.str.replace(\" \", \"_\", regex=False)\\n",
        "    s = s.str.replace(\"-\", \"_\", regex=False)\\n",
        "    return s\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5 — Ensure expected columns exist + apply cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in [\"user_id\", \"event_time\", \"event_type\", \"theme\", \"country\", \"channel\"]:\\n",
        "    if col not in events.columns:\\n",
        "        events[col] = \"\"\\n",
        "\\n",
        "events[\"user_id\"] = clean_str(events[\"user_id\"])\\n",
        "events[\"event_type\"] = normalize_event_type(events[\"event_type\"])\\n",
        "events[\"country\"] = normalize_country(events[\"country\"])\\n",
        "events[\"channel\"] = normalize_channel(events[\"channel\"])\\n",
        "\\n",
        "# theme: coerce numeric\\n",
        "events[\"theme\"] = pd.to_numeric(events[\"theme\"], errors=\"coerce\").astype(\"Int64\")\\n",
        "\\n",
        "# event_time: robust parse (dayfirst common in FR)\\n",
        "events[\"event_time\"] = pd.to_datetime(\\n",
        "    events[\"event_time\"],\\n",
        "    errors=\"coerce\",\\n",
        "    dayfirst=True,\\n",
        "    utc=True\\n",
        ")\\n",
        "\\n",
        "events.head(10)\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6 — Enrich from profiles (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if \"user_id\" in profiles.columns:\\n",
        "    profiles[\"user_id\"] = clean_str(profiles[\"user_id\"])\\n",
        "    if \"country\" in profiles.columns:\\n",
        "        profiles[\"country\"] = normalize_country(profiles[\"country\"])\\n",
        "    if \"channel\" in profiles.columns:\\n",
        "        profiles[\"channel\"] = normalize_channel(profiles[\"channel\"])\\n",
        "\\n",
        "    keep_cols = [c for c in [\"user_id\", \"country\", \"channel\"] if c in profiles.columns]\\n",
        "    prof_u = profiles[keep_cols].drop_duplicates(\"user_id\")\\n",
        "\\n",
        "    events = events.merge(prof_u, on=\"user_id\", how=\"left\", suffixes=(\"\", \"_profile\"))\\n",
        "\\n",
        "    if \"country_profile\" in events.columns:\\n",
        "        events[\"country\"] = events[\"country\"].mask(\\n",
        "            events[\"country\"].eq(\"\") | events[\"country\"].isna(),\\n",
        "            events[\"country_profile\"]\\n",
        "        )\\n",
        "    if \"channel_profile\" in events.columns:\\n",
        "        events[\"channel\"] = events[\"channel\"].mask(\\n",
        "            events[\"channel\"].eq(\"\") | events[\"channel\"].isna(),\\n",
        "            events[\"channel_profile\"]\\n",
        "        )\\n",
        "\\n",
        "    events.drop(columns=[c for c in [\"country_profile\", \"channel_profile\"] if c in events.columns], inplace=True)\\n",
        "\\n",
        "print(\"After enrich:\", events.shape)\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7 — Quality checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "expected_cols = [\"user_id\", \"event_time\", \"event_type\", \"theme\", \"country\", \"channel\"]\\n",
        "\\n",
        "report = {\\n",
        "    \"created_at\": datetime.utcnow().isoformat() + \"Z\",\\n",
        "    \"checks\": {}\\n",
        "}\\n",
        "\\n",
        "report[\"checks\"][\"rows_after_load\"] = int(len(events))\\n",
        "report[\"checks\"][\"has_expected_columns\"] = bool(all(c in events.columns for c in expected_cols))\\n",
        "\\n",
        "# missing\\n",
        "for c in expected_cols:\\n",
        "    report[\"checks\"][f\"missing_{c}\"] = int(events[c].isna().sum()) if c in events.columns else None\\n",
        "\\n",
        "# duplicates (full row duplicates)\\n",
        "report[\"checks\"][\"duplicate_rows\"] = int(events[expected_cols].duplicated().sum())\\n",
        "\\n",
        "# date range\\n",
        "dt_min = events[\"event_time\"].min()\\n",
        "dt_max = events[\"event_time\"].max()\\n",
        "report[\"checks\"][\"event_time_min\"] = None if pd.isna(dt_min) else dt_min.isoformat()\\n",
        "report[\"checks\"][\"event_time_max\"] = None if pd.isna(dt_max) else dt_max.isoformat()\\n",
        "\\n",
        "# distribution quick\\n",
        "report[\"checks\"][\"event_type_top10\"] = (\\n",
        "    events[\"event_type\"].value_counts(dropna=False).head(10).to_dict()\\n",
        ")\\n",
        "\\n",
        "report\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8 — Build clean dataset (exact schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean = events[expected_cols].copy()\\n",
        "\\n",
        "# minimal integrity\\n",
        "clean = clean.dropna(subset=[\"user_id\", \"event_time\", \"event_type\"])\\n",
        "clean = clean[clean[\"user_id\"].astype(str).str.len() > 0]\\n",
        "\\n",
        "# enforce dtypes where possible\\n",
        "clean[\"user_id\"] = clean[\"user_id\"].astype(str)\\n",
        "clean[\"event_type\"] = clean[\"event_type\"].astype(str)\\n",
        "clean[\"country\"] = clean[\"country\"].astype(str)\\n",
        "clean[\"channel\"] = clean[\"channel\"].astype(str)\\n",
        "\\n",
        "clean.to_csv(\"m2t2_clean_learning_dataset.csv\", index=False)\\n",
        "print(\"✅ Exported m2t2_clean_learning_dataset.csv\", clean.shape)\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 9 — Export quality report JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"m2t2_quality_report.json\", \"w\", encoding=\"utf-8\") as f:\\n",
        "    json.dump(report, f, ensure_ascii=False, indent=2)\\n",
        "\\n",
        "print(\"✅ Exported m2t2_quality_report.json\")\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 10 — Data dictionary markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict_lines = []\\n",
        "dict_lines.append(\"# Data Dictionary — Module 2 / Theme 2\\\\n\\\\n\")\\n",
        "dict_lines.append(\"## Schéma final (m2t2_clean_learning_dataset.csv)\\\\n\")\\n",
        "dict_lines.append(\"- **user_id**: identifiant apprenant (string)\\\\n\")\\n",
        "dict_lines.append(\"- **event_time**: date/heure événement (UTC, ISO)\\\\n\")\\n",
        "dict_lines.append(\"- **event_type**: type normalisé (ex: enrolled, opened_theme, opened_notebook, submitted, validated)\\\\n\")\\n",
        "dict_lines.append(\"- **theme**: numéro thème (int)\\\\n\")\\n",
        "dict_lines.append(\"- **country**: pays standardisé (Title Case)\\\\n\")\\n",
        "dict_lines.append(\"- **channel**: canal standardisé (lowercase)\\\\n\\\\n\")\\n",
        "dict_lines.append(\"## Notes qualité (extrait)\\\\n\")\\n",
        "dict_lines.append(f\"- rows_after_load: {report['checks'].get('rows_after_load')}\\\\n\")\\n",
        "dict_lines.append(f\"- duplicate_rows: {report['checks'].get('duplicate_rows')}\\\\n\")\\n",
        "dict_lines.append(f\"- event_time_min: {report['checks'].get('event_time_min')}\\\\n\")\\n",
        "dict_lines.append(f\"- event_time_max: {report['checks'].get('event_time_max')}\\\\n\")\\n",
        "\\n",
        "with open(\"m2t2_data_dictionary.md\", \"w\", encoding=\"utf-8\") as f:\\n",
        "    f.writelines(dict_lines)\\n",
        "\\n",
        "print(\"✅ Exported m2t2_data_dictionary.md\")\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 11 — Power Query M script presence check (student must paste it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m_path = \"m2t2_powerquery.m\"\\n",
        "if not os.path.exists(m_path):\\n",
        "    print(\"⚠️ m2t2_powerquery.m absent. Crée le fichier et colle ton script M depuis Power Query (Advanced Editor).\")\\n",
        "else:\\n",
        "    content = open(m_path, \"r\", encoding=\"utf-8\", errors=\"ignore\").read().strip()\\n",
        "    if len(content) < 30:\\n",
        "        print(\"⚠️ m2t2_powerquery.m présent mais trop court/vide. Colle le script M complet.\")\\n",
        "    else:\\n",
        "        print(\"✅ m2t2_powerquery.m OK (non vide).\")\\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

