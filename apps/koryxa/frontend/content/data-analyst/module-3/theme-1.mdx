import { CalloutInfo, CalloutTip, CalloutWarning } from "@/app/school/components/Callout";

export const meta = {
  title: "Thème 1 — Profilage & valeurs manquantes : diagnostiquer, choisir une stratégie, prouver",
  module: "Module 3 — Nettoyage & Qualité des données",
  estimated_reading_time: "120–150 min",
};

## 1) Objectif du thème

Dans un projet réel, “nettoyer” ne veut pas dire “remplir pour que le tableau paraisse complet”. Nettoyer veut dire préserver la fidélité de l’information tout en rendant les données utilisables. Une valeur manquante n’est pas seulement un vide : c’est un signal sur le système qui a produit la donnée, sur les conditions de collecte, ou sur le comportement des utilisateurs. Si tu remplaces des manquants sans comprendre leur origine, tu risques de fabriquer une histoire cohérente… mais fausse. C’est pour cela que ce thème suit une logique simple et professionnelle : diagnostiquer d’abord, décider ensuite, puis prouver ce que tu as fait avec des livrables reproductibles.

À la fin du thème, tu dois livrer quatre preuves concrètes : (1) un dataset nettoyé, (2) une table de profilage qui décrit la qualité colonne par colonne, (3) un rapport qualité au format JSON qui résume les métriques clés, et (4) un plan de traitement des valeurs manquantes en Markdown, où chaque décision est justifiée. Le but n’est pas d’être “certain” sur tout, mais d’être cohérent, transparent, et réplicable.

---

## 2) Profilage : diagnostiquer avant d’agir

Le profilage, c’est l’inventaire de santé de ton dataset. Avant de corriger, tu dois savoir ce que tu as entre les mains : quelles colonnes sont stables, lesquelles sont incohérentes, lesquelles sont exploitables, et lesquelles sont potentiellement dangereuses si tu les utilises sans contrôle. Dans la pratique, un profilage “minimum pro” fournit, pour chaque colonne, le type logique (numérique/catégorie/date), le taux de valeurs manquantes, le nombre de valeurs uniques, et des statistiques adaptées au type (top valeurs et fréquences pour les catégories, min/max pour les numériques, plage min/max et anomalies de parsing pour les dates). Le profilage doit aussi signaler des valeurs suspectes : âges à 0 ou 999, revenus négatifs, dates invalides, catégories “vides” masquées par des espaces.

### 2.1 Ce qu’on mesure (minimum pro)

Tu produis une table de profilage où chaque ligne représente une colonne. Elle doit contenir au minimum : `column`, `dtype`, `%missing`, `n_unique`, `top_3_values`, `min`, `max`, et `suspects`. Cette table devient ton point de départ : elle te permet de distinguer les problèmes “mineurs” (ex : casse incohérente) des problèmes “bloquants” (ex : identifiant manquant, dates impossibles, revenus négatifs).

Exemple (extrait attendu) :

| column | dtype | pct_missing | n_unique | top_3_values | min | max | suspects |
|---|---|---:|---:|---|---:|---:|---|
| age | Int64 | 0.18 | 56 | — | 0 | 999 | 0/999 |
| country | string | 0.07 | 9 | TG:120, gh:40, "":15 | — | — | espaces/casse |
| signup_date | datetime64[ns] | 0.03 | 240 | — | — | — | formats mixtes |

### 2.2 NA ≠ “vide”

En pandas, “manquant” peut être NaN (numérique), `<NA>`/None (texte), NaT (dates). Une chaîne vide `""` n’est pas toujours un manquant : si le métier considère que vide = inconnu, tu dois la convertir explicitement.

<CalloutWarning title="Règle critique">
  Ne convertis pas tout en texte (`astype(str)`) au nettoyage : sinon NaN devient `"nan"` et tu perds l’information de manquant.
</CalloutWarning>

---

## 3) Valeurs manquantes : comprendre le mécanisme

On distingue classiquement :
- MCAR : manque au hasard → biais souvent limité
- MAR : manque dépend d’une variable observée
- MNAR : manque dépend de la valeur elle-même → risque de biais plus élevé

Tu ne peux pas “prouver” parfaitement MCAR/MAR/MNAR sur un simple export. En revanche, tu peux faire un diagnostic raisonnable :
- créer un indicateur `is_missing_X`,
- comparer pays/canal/âge entre “missing” et “non-missing”,
- vérifier si le missing est concentré sur certains segments.

<CalloutInfo title="Règle">
  Tu documentes ton hypothèse et ton incertitude.
</CalloutInfo>

---

## 4) Stratégies de traitement : quoi faire, quand, et pourquoi

### 4.1 Supprimer (drop)

Supprimer peut être acceptable si la colonne est non critique et trop manquante, ou si la ligne est inutilisable (ex : `user_id` manquant).

<CalloutWarning title="Attention (biais)">
  Supprimer beaucoup de lignes peut changer l’échantillon. Toujours mesurer l’impact “avant/après”.
</CalloutWarning>

### 4.2 Imputer (fill)

Stratégies simples et reproductibles :
- numérique : médiane (robuste),
- catégoriel : mode, ou `Unknown`,
- dates : souvent garder NA + ajouter un indicateur (selon le métier).

<CalloutTip title="Règle pro">
  Si tu imputes, ajoute un indicateur `missing_&lt;col&gt;` pour conserver l’information de manque.
</CalloutTip>

### 4.3 Créer “Unknown”

Utile pour des catégories (channel, city, device). `Unknown` devient un segment : il faut le mesurer.

### 4.4 Imputation avancée (hors fondamental)

KNN/modèles : possible, mais plus risqué si mal expliqué. Priorité : clarté, traçabilité, reproductibilité.

---

## 5) Mini-cas KORYXA : `sales_users_messy.csv`

Colonnes : `user_id`, `country`, `channel`, `age`, `signup_date`, `last_active`, `revenue`.

Problèmes injectés :
- âges manquants + âges aberrants (0, 999),
- dates en formats mixtes,
- country vide / espaces / casse incohérente,
- revenue manquant (MNAR possible) + revenue négatif,
- doublons sur `user_id`.

Objectif (exports obligatoires) :
- `m3t1_dataset_clean.csv`
- `m3t1_quality_report.json`
- `m3t1_missingness_plan.md`
- `m3t1_profiling_table.csv`

---

## 6) Plan de traitement (format simple obligatoire)

| Colonne | % missing | Hypothèse mécanisme | Décision | Justification |
|---|---:|---|---|---|
| age | … | MAR possible | médiane + flag | robuste, variable utile |
| country | … | MCAR/MAR | Unknown + nettoyage | évite drop |
| revenue | … | MNAR possible | garder NA + flag | éviter biais |

---

## 7) Exécution obligatoire (notebook)

Le notebook doit :
- faire le profilage complet,
- faire le nettoyage minimal,
- appliquer la stratégie missingness (simple + flag),
- dédupliquer proprement,
- exporter les 4 fichiers.

Le quiz lit uniquement ces fichiers : impossible de réussir sans exécution.

---

## 8) Checklist validation

- `m3t1_profiling_table.csv` généré
- `m3t1_dataset_clean.csv` généré
- `m3t1_quality_report.json` généré
- `m3t1_missingness_plan.md` généré
- Soumission validée → quiz débloqué
