{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 3 — Thème 2\\n",
        "\\n",
        "Doublons, clés, unicité, déduplication contrôlée.\\n",
        "\\n",
        "Fichiers attendus en sortie :\\n",
        "- m3t2_key_audit.csv\\n",
        "- m3t2_duplicates_report.csv\\n",
        "- m3t2_dataset_dedup.csv\\n",
        "- m3t2_dedup_audit.csv\\n",
        "- m3t2_quality_report.json\\n",
        "- m3t2_dedup_rules.md\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd, json\\n",
        "from datetime import datetime\\n",
        "\\n",
        "df = pd.read_csv(\"users_identity_messy.csv\")\\n",
        "\\n",
        "# -----------------------------\\n",
        "# 1) Nettoyage minimal (avant audit)\\n",
        "# -----------------------------\\n",
        "def clean_str(s: pd.Series):\\n",
        "    s = s.astype(\"string\")\\n",
        "    s = s.str.strip().str.replace(r\"\\\\s+\", \" \", regex=True)\\n",
        "    return s\\n",
        "\\n",
        "for c in [\"user_id\", \"email\", \"phone\", \"country\", \"channel\"]:\\n",
        "    df[c] = clean_str(df[c])\\n",
        "\\n",
        "# normalisations utiles\\n",
        "df[\"email\"] = df[\"email\"].replace({\"\": pd.NA}).str.lower()\\n",
        "df[\"phone\"] = df[\"phone\"].replace({\"\": pd.NA})\\n",
        "df[\"country\"] = df[\"country\"].replace({\"\": pd.NA}).str.title()\\n",
        "df[\"channel\"] = df[\"channel\"].replace({\"\": pd.NA}).str.lower()\\n",
        "\\n",
        "df[\"signup_date\"] = pd.to_datetime(df[\"signup_date\"], errors=\"coerce\", dayfirst=True, utc=True)\\n",
        "df[\"last_active\"] = pd.to_datetime(df[\"last_active\"], errors=\"coerce\", dayfirst=True, utc=True)\\n",
        "df[\"revenue\"] = pd.to_numeric(df[\"revenue\"], errors=\"coerce\")\\n",
        "df.loc[df[\"revenue\"] < 0, \"revenue\"] = pd.NA\\n",
        "\\n",
        "# -----------------------------\\n",
        "# 2) Audit des clés candidates\\n",
        "# -----------------------------\\n",
        "candidates = {\\n",
        "    \"user_id\": [\"user_id\"],\\n",
        "    \"email\": [\"email\"],\\n",
        "    \"phone\": [\"phone\"],\\n",
        "    \"email_or_phone\": None,  # calculée après\\n",
        "}\\n",
        "\\n",
        "tmp = df.copy()\\n",
        "tmp[\"email_or_phone\"] = tmp[\"email\"].fillna(tmp[\"phone\"])\\n",
        "\\n",
        "audit_rows = []\\n",
        "for name, cols in candidates.items():\\n",
        "    if cols is None:\\n",
        "        key = tmp[\"email_or_phone\"]\\n",
        "        n_unique = int(key.nunique(dropna=True))\\n",
        "        dup_rows = int(key.duplicated(keep=False).sum())\\n",
        "    else:\\n",
        "        n_unique = int(tmp[cols].drop_duplicates().shape[0])\\n",
        "        dup_rows = int(tmp.duplicated(subset=cols, keep=False).sum())\\n",
        "\\n",
        "    audit_rows.append({\\n",
        "        \"candidate_key\": name,\\n",
        "        \"n_rows\": int(len(tmp)),\\n",
        "        \"n_unique\": n_unique,\\n",
        "        \"duplicate_rows\": dup_rows,\\n",
        "        \"duplicate_rate_pct\": round((dup_rows / len(tmp)) * 100, 2),\\n",
        "    })\\n",
        "\\n",
        "audit_df = pd.DataFrame(audit_rows).sort_values(\"duplicate_rate_pct\", ascending=True)\\n",
        "audit_df.to_csv(\"m3t2_key_audit.csv\", index=False)\\n",
        "\\n",
        "# -----------------------------\\n",
        "# 3) Rapport doublons (résumé)\\n",
        "# -----------------------------\\n",
        "report = []\\n",
        "\\n",
        "# Doublons exacts (lignes identiques)\\n",
        "exact_dupes = int(tmp.duplicated(keep=False).sum())\\n",
        "report.append({\"type\": \"exact_row_duplicates\", \"key\": \"ALL_COLUMNS\", \"duplicate_rows\": exact_dupes})\\n",
        "\\n",
        "# Doublons par colonnes\\n",
        "for k, cols in [(\"user_id\", [\"user_id\"]), (\"email\", [\"email\"]), (\"phone\", [\"phone\"])]:\\n",
        "    dup_rows = int(tmp.duplicated(subset=cols, keep=False).sum())\\n",
        "    report.append({\"type\": \"key_duplicates\", \"key\": k, \"duplicate_rows\": dup_rows})\\n",
        "\\n",
        "# Doublons identité (email_or_phone)\\n",
        "dup_rows_entity = int(tmp[\"email_or_phone\"].duplicated(keep=False).sum())\\n",
        "report.append({\"type\": \"entity_duplicates\", \"key\": \"email_or_phone\", \"duplicate_rows\": dup_rows_entity})\\n",
        "\\n",
        "pd.DataFrame(report).to_csv(\"m3t2_duplicates_report.csv\", index=False)\\n",
        "\\n",
        "# -----------------------------\\n",
        "# 4) Déduplication contrôlée\\n",
        "#    - clé entité = email si présent sinon phone sinon user_id\\n",
        "#    - garder: plus complet, puis plus récent\\n",
        "# -----------------------------\\n",
        "work = tmp.copy()\\n",
        "\\n",
        "work[\"entity_id\"] = work[\"email\"].fillna(work[\"phone\"]).fillna(work[\"user_id\"])\\n",
        "\\n",
        "# score de complétude (combien de champs utiles non manquants)\\n",
        "useful_cols = [\"country\", \"channel\", \"signup_date\", \"last_active\", \"revenue\", \"email\", \"phone\"]\\n",
        "work[\"completeness_score\"] = work[useful_cols].notna().sum(axis=1)\\n",
        "\\n",
        "# tri: entity_id, completeness desc, last_active desc\\n",
        "work = work.sort_values(\\n",
        "    by=[\"entity_id\", \"completeness_score\", \"last_active\"],\\n",
        "    ascending=[True, False, False],\\n",
        ")\\n",
        "\\n",
        "# marquer la ligne gardée\\n",
        "work[\"is_kept\"] = ~work.duplicated(subset=[\"entity_id\"], keep=\"first\")\\n",
        "\\n",
        "kept = work[work[\"is_kept\"]].drop(columns=[\"completeness_score\", \"is_kept\"])\\n",
        "dropped = work[~work[\"is_kept\"]].copy()\\n",
        "\\n",
        "# audit des suppressions\\n",
        "audit = dropped[[\"entity_id\", \"user_id\", \"email\", \"phone\", \"last_active\", \"country\", \"channel\", \"revenue\"]].copy()\\n",
        "audit[\"reason\"] = \"duplicate_entity_id_keep_best(completeness, last_active)\"\\n",
        "audit.to_csv(\"m3t2_dedup_audit.csv\", index=False)\\n",
        "\\n",
        "# dataset final dédupliqué\\n",
        "kept.to_csv(\"m3t2_dataset_dedup.csv\", index=False)\\n",
        "\\n",
        "# -----------------------------\\n",
        "# 5) Rapport qualité\\n",
        "# -----------------------------\\n",
        "quality = {\\n",
        "  \"created_at\": datetime.utcnow().isoformat()+\"Z\",\\n",
        "  \"rows_before\": int(len(tmp)),\\n",
        "  \"rows_after\": int(len(kept)),\\n",
        "  \"dropped_rows\": int(len(tmp) - len(kept)),\\n",
        "  \"unique_entity_id\": int(kept[\"entity_id\"].nunique(dropna=True)),\\n",
        "  \"checks\": {\\n",
        "    \"entity_id_unique\": bool(kept[\"entity_id\"].is_unique),\\n",
        "    \"rows_ge_200\": bool(len(kept) >= 200),\\n",
        "    \"dropped_at_least_one\": bool((len(tmp) - len(kept)) >= 1),\\n",
        "  },\\n",
        "}\\n",
        "with open(\"m3t2_quality_report.json\", \"w\", encoding=\"utf-8\") as f:\\n",
        "    json.dump(quality, f, ensure_ascii=False, indent=2)\\n",
        "\\n",
        "rules = f\"\"\"# Dedup Rules — Module 3 Theme 2\\n",
        "\\n",
        "## Entity key\\n",
        "entity_id = email if present else phone if present else user_id\\n",
        "\\n",
        "## Pre-cleaning\\n",
        "- email: strip + lowercase + empty -> NA\\n",
        "- country: strip + Title Case + empty -> NA\\n",
        "- channel: strip + lowercase + empty -> NA\\n",
        "- dates: parsed to UTC where possible\\n",
        "\\n",
        "## Selection rule (per entity_id)\\n",
        "1) Keep row with highest completeness_score (non-missing among: {useful_cols})\\n",
        "2) If tie, keep most recent last_active\\n",
        "3) Else stable first after sort\\n",
        "\\n",
        "## Evidence exports\\n",
        "- m3t2_key_audit.csv\\n",
        "- m3t2_duplicates_report.csv\\n",
        "- m3t2_dedup_audit.csv (dropped rows)\\n",
        "- m3t2_dataset_dedup.csv (final)\\n",
        "\"\"\"\\n",
        "open(\"m3t2_dedup_rules.md\", \"w\", encoding=\"utf-8\").write(rules)\\n",
        "\\n",
        "print(\"✅ Exports generated (audit/report/dedup/quality/rules).\")\\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

