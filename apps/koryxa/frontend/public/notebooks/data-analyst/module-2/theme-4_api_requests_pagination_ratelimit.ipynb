{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 2 · Thème 4 — API requests, pagination, rate limit\n",
        "\n",
        "Ce notebook appelle le Mock API KORYXA (auth `X-API-Key`), suit `next`, gère les 429, logge chaque requête puis produit ",
        "- `m2t4_transactions_raw.csv`\n",
        "- `m2t4_transactions_clean.csv`\n",
        "- `m2t4_request_log.csv`\n",
        "- `m2t4_run_report.json`\n",
        "- `m2t4_api_contract.md`\n",
        "\n",
        "Le code suit strictement : pagination via `next`, retries intelligents, timeout + `raise_for_status()`, log d’erreurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, time, json\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from urllib.parse import urljoin, urlparse, parse_qs\n",
        "\n",
        "BASE = os.getenv(\"KORYXA_LAB_API_BASE\", \"http://localhost:8000\").rstrip(\"/\")\n",
        "API_KEY = os.getenv(\"KORYXA_LAB_API_KEY\", \"CHANGE_ME\")\n",
        "\n",
        "START_URL = f\"{BASE}/api/labs/mock-api/v1/transactions\"\n",
        "PARAMS = {\"page\": 1, \"page_size\": 100, \"start_date\": \"2026-01-01\", \"end_date\": \"2026-01-31\"}\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers.update({\n",
        "    \"Accept\": \"application/json\",\n",
        "    \"X-API-Key\": API_KEY,\n",
        "})\n",
        "\n",
        "request_log = []\n",
        "all_rows = []\n",
        "n_429 = 0\n",
        "\n",
        "def log_req(url, params, status_code, elapsed_ms, bytes_len, error=\"\"):\n",
        "    request_log.append({\n",
        "        \"ts\": datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"url\": url,\n",
        "        \"params\": json.dumps(params or {}, ensure_ascii=False),\n",
        "        \"status_code\": status_code,\n",
        "        \"elapsed_ms\": int(elapsed_ms),\n",
        "        \"bytes\": int(bytes_len),\n",
        "        \"error\": error\n",
        "    })\n",
        "\n",
        "def sleep_backoff(attempt, base=0.5, cap=8.0):\n",
        "    t = min(cap, base * (2 ** attempt))\n",
        "    time.sleep(t)\n",
        "\n",
        "url = START_URL\n",
        "params = PARAMS.copy()\n",
        "max_pages = 1000\n",
        "page_count = 0\n",
        "while True:\n",
        "    page_count += 1\n",
        "    if page_count > max_pages:\n",
        "        raise RuntimeError(\"Pagination safety stop: too many pages (possible loop).\")\n",
        "    for attempt in range(6):\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            r = session.get(url, params=params, timeout=15)\n",
        "            elapsed_ms = (time.time() - t0) * 1000\n",
        "            log_req(url, params, r.status_code, elapsed_ms, len(r.content or b\"\"))\n",
        "\n",
        "            if r.status_code == 429:\n",
        "                n_429 += 1\n",
        "                retry_after = int(r.headers.get(\"Retry-After\", \"2\"))\n",
        "                time.sleep(min(max(retry_after, 1), 10))\n",
        "                continue\n",
        "\n",
        "            if 500 <= r.status_code < 600:\n",
        "                sleep_backoff(attempt)\n",
        "                continue\n",
        "\n",
        "            r.raise_for_status()\n",
        "            payload = r.json()\n",
        "            break\n",
        "\n",
        "        except (requests.Timeout, requests.ConnectionError) as e:\n",
        "            elapsed_ms = (time.time() - t0) * 1000\n",
        "            log_req(url, params, -1, elapsed_ms, 0, error=f\"{type(e).__name__}: {e}\")\n",
        "            sleep_backoff(attempt)\n",
        "            continue\n",
        "\n",
        "        except ValueError as e:\n",
        "            elapsed_ms = (time.time() - t0) * 1000\n",
        "            log_req(url, params, r.status_code if 'r' in locals() else -1, elapsed_ms, len(getattr(r, 'content', b'') or b''), error=f\"JSONDecodeError: {e}\")\n",
        "            raise\n",
        "    else:\n",
        "        raise RuntimeError(\"Failed after retries (page fetch).\")\n",
        "\n",
        "    all_rows.extend(payload.get(\"results\", []))\n",
        "    nxt = payload.get(\"next\")\n",
        "    if not nxt:\n",
        "        break\n",
        "\n",
        "    url = urljoin(BASE + \"/\", nxt.lstrip(\"/\"))\n",
        "    parsed = urlparse(url)\n",
        "    qs = parse_qs(parsed.query)\n",
        "    params = {k: (v[0] if isinstance(v, list) and v else v) for k, v in qs.items()}\n",
        "    url = f\"{parsed.scheme}://{parsed.netloc}{parsed.path}\"\n",
        "    time.sleep(0.2)\n",
        "df_raw = pd.DataFrame(all_rows)\n",
        "df_raw.to_csv(\"m2t4_transactions_raw.csv\", index=False)\n",
        "df = df_raw.copy()\n",
        "if not df.empty:\n",
        "    df[\"amount\"] = pd.to_numeric(df.get(\"amount\"), errors=\"coerce\")\n",
        "    df[\"created_at\"] = pd.to_datetime(df.get(\"created_at\"), errors=\"coerce\", utc=True)\n",
        "    df[\"country\"] = df.get(\"country\", \"\").astype(str).str.strip().str.title()\n",
        "    df[\"channel\"] = df.get(\"channel\", \"\").astype(str).str.strip().str.lower()\n",
        "    df[\"currency\"] = df.get(\"currency\", \"\").astype(str).str.strip().str.upper()\n",
        "df.to_csv(\"m2t4_transactions_clean.csv\", index=False)\n",
        "pd.DataFrame(request_log).to_csv(\"m2t4_request_log.csv\", index=False)\n",
        "run_report = {\n",
        "  \"created_at\": datetime.utcnow().isoformat() + \"Z\",\n",
        "  \"requests_made\": int(len(request_log)),\n",
        "  \"rows_fetched\": int(len(df_raw)),\n",
        "  \"n_429\": int(n_429),\n",
        "  \"date_min\": None if df.empty or df[\"created_at\"].isna().all() else df[\"created_at\"].min().isoformat(),\n",
        "  \"date_max\": None if df.empty or df[\"created_at\"].isna().all() else df[\"created_at\"].max().isoformat()\n",
        "}\n",
        "with open(\"m2t4_run_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(run_report, f, ensure_ascii=False, indent=2)\n",
        "contract = f\"\"\"# API Contract — Theme 4\n\n## Endpoint\nGET /api/labs/mock-api/v1/transactions\n\n## Auth\nX-API-Key: (hidden)\n\n## Params\npage, page_size, start_date, end_date, country (optional)\n\n## Pagination\nFollow `next` until null.\n\n## Rate limit\n429 Too Many Requests + Retry-After\n\n## Evidence\nrows_fetched: {run_report['rows_fetched']}\nrequests_made: {run_report['requests_made']}\nn_429: {run_report['n_429']}\n\"\"\"\n",
        "with open(\"m2t4_api_contract.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(contract)\n",
        "print(\"✅ Exports generated (raw/clean/log/report/contract).\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
