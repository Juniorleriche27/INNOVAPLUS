{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 2 — Theme 1 — Source inventory + data mapping + plan de collecte\\n",
        "\\n",
        "Ce notebook génère les preuves obligatoires :\\n",
        "- `m2t1_inventory_filled.csv`\\n",
        "- `m2t1_data_mapping.md`\\n",
        "- `m2t1_collection_plan.md`\\n",
        "- `m2t1_quality_checks.json`\\n",
        "\\n",
        "Fichiers d'entrée attendus (dans le même dossier que le notebook) :\\n",
        "- `source_inventory_template.csv`\\n",
        "- `data_requirements_template.csv`\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\\n",
        "import json\\n",
        "from datetime import datetime\\n",
        "\\n",
        "inv = pd.read_csv(\"source_inventory_template.csv\")\\n",
        "req = pd.read_csv(\"data_requirements_template.csv\")\\n",
        "\\n",
        "# --- Minimal validation rules ---\\n",
        "required_inv_cols = {\\n",
        "  \"source_name\",\"type\",\"owner\",\"access\",\"refresh\",\"grain\",\\n",
        "  \"key_fields\",\"coverage\",\"known_issues\",\"privacy\",\"linked_kpis\"\\n",
        "}\\n",
        "missing = required_inv_cols - set(inv.columns)\\n",
        "if missing:\\n",
        "    raise ValueError(f\"Missing inventory columns: {missing}\")\\n",
        "\\n",
        "if len(inv) < 8:\\n",
        "    raise ValueError(f\"Inventory must have >= 8 sources. Current: {len(inv)}\")\\n",
        "\\n",
        "if len(req) < 10:\\n",
        "    raise ValueError(f\"Data requirements must have >= 10 rows. Current: {len(req)}\")\\n",
        "\\n",
        "if inv[\"source_name\"].duplicated().any():\\n",
        "    raise ValueError(\"Duplicate source_name in inventory.\")\\n",
        "\\n",
        "if inv[\"key_fields\"].fillna(\"\").str.len().eq(0).any():\\n",
        "    raise ValueError(\"Some sources have empty key_fields.\")\\n",
        "\\n",
        "# --- Export inventory ---\\n",
        "inv.to_csv(\"m2t1_inventory_filled.csv\", index=False)\\n",
        "\\n",
        "# --- Data mapping markdown ---\\n",
        "mapping_lines = []\\n",
        "mapping_lines.append(\"# Data mapping — Module 2 / Theme 1\\n\")\\n",
        "mapping_lines.append(\"\\n## Sources inventory\\n\")\\n",
        "for _, r in inv.iterrows():\\n",
        "    mapping_lines.append(\\n",
        "        f\"- **{r['source_name']}** ({r['type']}) — grain: {r['grain']} — key_fields: `{r['key_fields']}`\"\\n",
        "    )\\n",
        "\\n",
        "mapping_lines.append(\"\\n## Proposed joins (minimal)\\n\")\\n",
        "mapping_lines.append(\"- `platform_events.user_id` -> `validations.user_id`\")\\n",
        "mapping_lines.append(\"- `platform_events.user_id` -> `profile.user_id`\")\\n",
        "mapping_lines.append(\"- `platform_events.user_id` -> `marketing.user_id`\")\\n",
        "mapping_lines.append(\"- `platform_events.user_id` -> `support_tickets.user_id`\")\\n",
        "\\n",
        "mapping_lines.append(\"\\n## Join risks to check\\n\")\\n",
        "mapping_lines.append(\"- Verify `user_id` type consistency across sources (string/int).\")\\n",
        "mapping_lines.append(\"- Check missing `user_id` rates and orphan records after joins.\")\\n",
        "mapping_lines.append(\"- Confirm grain before aggregations (event vs user vs ticket).\")\\n",
        "\\n",
        "with open(\"m2t1_data_mapping.md\", \"w\", encoding=\"utf-8\") as f:\\n",
        "    f.write(\"\\n\".join(mapping_lines))\\n",
        "\\n",
        "# --- Collection plan markdown ---\\n",
        "plan = []\\n",
        "plan.append(\"# Data collection plan — Module 2 / Theme 1\\n\")\\n",
        "plan.append(\"\\n## Goal\\n\")\\n",
        "plan.append(\"- Build a reproducible source inventory + mapping + collection plan.\\n\")\\n",
        "plan.append(\"\\n## Steps (recommended order)\\n\")\\n",
        "plan.append(\"1) Confirm access owners + credentials (SQL/API/exports)\\n\")\\n",
        "plan.append(\"2) Extract priority sources (platform_events, validations)\\n\")\\n",
        "plan.append(\"3) Run express quality checks (missing, duplicates, date ranges)\\n\")\\n",
        "plan.append(\"4) Extract segmentation sources (profile, marketing)\\n\")\\n",
        "plan.append(\"5) Extract guardrail sources (support_tickets)\\n\")\\n",
        "plan.append(\"6) Store extracts in a date-stamped folder (versioning)\\n\")\\n",
        "plan.append(\"7) Document assumptions + limitations\\n\")\\n",
        "plan.append(\"\\n## Storage convention\\n\")\\n",
        "plan.append(\"- `extracts/YYYY-MM-DD/<source_name>.<ext>`\\n\")\\n",
        "plan.append(\"- `extracts/YYYY-MM-DD/README_extraction.md`\\n\")\\n",
        "plan.append(\"\\n## Validation\\n\")\\n",
        "plan.append(\"- Inventory rows >= 8\\n\")\\n",
        "plan.append(\"- Requirements rows >= 10\\n\")\\n",
        "plan.append(\"- Mapping includes 4+ joins\\n\")\\n",
        "\\n",
        "with open(\"m2t1_collection_plan.md\", \"w\", encoding=\"utf-8\") as f:\\n",
        "    f.write(\"\\n\".join(plan))\\n",
        "\\n",
        "# --- Quick quality checks summary ---\\n",
        "qc = {\\n",
        "  \"created_at\": datetime.utcnow().isoformat() + \"Z\",\\n",
        "  \"inventory_rows\": int(len(inv)),\\n",
        "  \"requirements_rows\": int(len(req)),\\n",
        "  \"checks\": [\\n",
        "    {\"name\": \"inventory_min_8_sources\", \"ok\": len(inv) >= 8},\\n",
        "    {\"name\": \"requirements_min_10_fields\", \"ok\": len(req) >= 10},\\n",
        "    {\"name\": \"unique_source_name\", \"ok\": bool(~inv[\"source_name\"].duplicated().any())},\\n",
        "    {\"name\": \"has_key_fields\", \"ok\": bool(inv[\"key_fields\"].fillna(\"\").str.len().gt(0).all())}\\n",
        "  ]\\n",
        "}\\n",
        "\\n",
        "with open(\"m2t1_quality_checks.json\", \"w\", encoding=\"utf-8\") as f:\\n",
        "    json.dump(qc, f, ensure_ascii=False, indent=2)\\n",
        "\\n",
        "print(\"✅ Exports generated:\",\\n",
        "      \"m2t1_inventory_filled.csv, m2t1_data_mapping.md, m2t1_collection_plan.md, m2t1_quality_checks.json\")\\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

